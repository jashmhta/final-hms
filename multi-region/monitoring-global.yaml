# Multi-Region Monitoring Configuration
# Enterprise-grade global monitoring and alerting for HMS microservices

apiVersion: v1
kind: ConfigMap
metadata:
  name: global-monitoring-config
  namespace: monitoring
  labels:
    app.kubernetes.io/name: global-monitoring
    app.kubernetes.io/part-of: hms
    app.kubernetes.io/component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: '{{ .Values.cluster | default "unknown" }}'
        region: '{{ .Values.region | default "unknown" }}'

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager.monitoring.svc.cluster.local:9093

    # Rule files
    rule_files:
    - "/etc/prometheus/rules/*.yml"
    - "/etc/prometheus/rules/*.yaml"

    # Scrape configurations
    scrape_configs:

    # Prometheus self-monitoring
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
      metrics_path: /metrics
      scrape_interval: 30s
      scrape_timeout: 10s

    # Kubernetes API server
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

    # Kubernetes nodes
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # Kubernetes pods
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

    # HMS microservices
    - job_name: 'hms-microservices'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name

    # PostgreSQL monitoring
    - job_name: 'postgres-exporter'
      static_configs:
      - targets: ['postgres-exporter.monitoring.svc.cluster.local:9187']
      scrape_interval: 30s
      metrics_path: /metrics

    # Redis monitoring
    - job_name: 'redis-exporter'
      static_configs:
      - targets: ['redis-exporter.monitoring.svc.cluster.local:9121']
      scrape_interval: 30s
      metrics_path: /metrics

    # Istio monitoring
    - job_name: 'istio-mesh'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_port_name]
        action: keep
        regex: 'http-monitoring'
      - source_labels: [__meta_kubernetes_pod_container_name]
        action: keep
        regex: 'istio-proxy'

    # Global health checks
    - job_name: 'global-health-checks'
      static_configs:
      - targets:
        - 'https://api.hms.enterprise.com/health'
        - 'https://api-secondary.hms.enterprise.com/health'
        - 'https://api-tertiary.hms.enterprise.com/health'
      metrics_path: /metrics
      scrape_interval: 60s
      scheme: https
      tls_config:
        insecure_skip_verify: true

    # Cross-region federation
    - job_name: 'federate'
      honor_labels: true
      metrics_path: /federate
      params:
        'match[]':
        - '{job=~"hms-microservices|postgres-exporter|redis-exporter"}'
        - '{__name__=~"up|container_cpu_usage_seconds_total|container_memory_usage_bytes"}'
      static_configs:
      - targets:
        - 'prometheus-secondary.monitoring.svc.cluster.local:9090'
        - 'prometheus-tertiary.monitoring.svc.cluster.local:9090'
      scrape_interval: 30s
      scrape_timeout: 10s

    # Blackbox exporter for external monitoring
    - job_name: 'blackbox'
      metrics_path: /probe
      params:
        module: [http_2xx]
      static_configs:
      - targets:
        - 'https://api.hms.enterprise.com'
        - 'https://monitoring.hms.enterprise.com'
        - 'https://grafana.hms.enterprise.com'
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.monitoring.svc.cluster.local:9115

  rules.yml: |
    groups:
    - name: global-health
      rules:
      - alert: GlobalServiceDown
        expr: up{job="global-health-checks"} == 0
        for: 2m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Global service is down"
          description: "Global service {{ $labels.instance }} has been down for more than 2 minutes"

      - alert: CrossRegionLatencyHigh
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="global-health-checks"}[5m])) > 2
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Cross-region latency is high"
          description: "95th percentile latency for {{ $labels.instance }} is {{ $value }}s"

      - alert: RegionFailure
        expr: count(up{job="global-health-checks"} == 0) by (region) >= 2
        for: 1m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Region failure detected"
          description: "Multiple services in region {{ $labels.region }} are failing"

    - name: database-health
      rules:
      - alert: PostgreSQLReplicationLag
        expr: pg_stat_replication_replication_lag > 30
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "PostgreSQL replication lag is high"
          description: "PostgreSQL replication lag is {{ $value }} seconds"

      - alert: PostgreSQLDown
        expr: up{job="postgres-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      - alert: RedisDown
        expr: up{job="redis-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is down"

    - name: microservices-health
      rules:
      - alert: MicroserviceHighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Microservice error rate is high"
          description: "Microservice {{ $labels.service }} has error rate of {{ $value | humanizePercentage }}"

      - alert: MicroserviceHighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Microservice latency is high"
          description: "Microservice {{ $labels.service }} has 95th percentile latency of {{ $value }}s"

      - alert: MicroserviceDown
        expr: up{job="hms-microservices"} == 0
        for: 1m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Microservice is down"
          description: "Microservice {{ $labels.service }} is down"

    - name: kubernetes-health
      rules:
      - alert: KubernetesNodeDown
        expr: kube_node_status_condition{condition="Ready", status="true"} == 0
        for: 5m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Kubernetes node is down"
          description: "Kubernetes node {{ $labels.node }} is not ready"

      - alert: KubernetesPodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[5m]) > 0
        for: 10m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Kubernetes pod is crash looping"
          description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"

    - name: storage-health
      rules:
      - alert: DiskSpaceCritical
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: critical
          region: global
        annotations:
          summary: "Disk space is critical"
          description: "Disk space on {{ $labels.instance }} is {{ $value }}% full"

      - alert: DiskSpaceWarning
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 80
        for: 10m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Disk space is warning"
          description: "Disk space on {{ $labels.instance }} is {{ $value }}% full"

    - name: network-health
      rules:
      - alert: NetworkLatencyHigh
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Network latency is high"
          description: "Network latency to {{ $labels.instance }} is {{ $value }}s"

      - alert: NetworkPacketLoss
        expr: rate(node_network_receive_drop_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          region: global
        annotations:
          summary: "Network packet loss detected"
          description: "Network packet loss rate on {{ $labels.instance }} is {{ $value }} packets/sec"
---
# Global Grafana configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: global-grafana-config
  namespace: monitoring
  labels:
    app.kubernetes.io/name: global-grafana
    app.kubernetes.io/part-of: hms
    app.kubernetes.io/component: monitoring
data:
  grafana.ini: |
    [server]
    root_url = https://grafana.hms.enterprise.com
    serve_from_sub_path = true

    [security]
    admin_user = admin
    admin_password = ${GRAFANA_ADMIN_PASSWORD}
    secret_key = ${GRAFANA_SECRET_KEY}

    [database]
    type = postgres
    host = postgres-primary.hms-system.svc.cluster.local:5432
    name = grafana
    user = grafana
    password = ${GRAFANA_DB_PASSWORD}
    ssl_mode = require

    [users]
    allow_sign_up = false
    auto_assign_org = true
    auto_assign_org_role = Viewer

    [auth]
    disable_login_form = false

    [auth.anonymous]
    enabled = false

    [alerting]
    enabled = true
    execute_alerts = true

    [metrics]
    enabled = true

    [log]
    level = info

    [log.console]
    format = text

    [paths]
    data = /var/lib/grafana
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning

    [remote_cache]
    type = redis
    connstr = addr=redis-primary.hms-system.svc.cluster.local:6379, password=${REDIS_PASSWORD}, db=0

  dashboards.yml: |
    apiVersion: 1

    providers:
    - name: 'default'
      orgId: 1
      folder: 'HMS Global'
      type: file
      disableDeletion: false
      updateIntervalSeconds: 10
      allowUiUpdates: true
      options:
        path: /etc/grafana/dashboards

  datasources.yml: |
    apiVersion: 1

    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      orgId: 1
      url: http://prometheus.monitoring.svc.cluster.local:9090
      basicAuth: false
      isDefault: true
      version: 1
      editable: false
      jsonData:
        httpMethod: POST
        queryTimeout: 60s
        timeInterval: 15s

    - name: Prometheus-Secondary
      type: prometheus
      access: proxy
      orgId: 1
      url: http://prometheus-secondary.monitoring.svc.cluster.local:9090
      basicAuth: false
      isDefault: false
      version: 1
      editable: false
      jsonData:
        httpMethod: POST
        queryTimeout: 60s
        timeInterval: 15s

    - name: PostgreSQL
      type: postgres
      access: proxy
      orgId: 1
      url: postgres-primary.hms-system.svc.cluster.local:5432
      database: hms
      user: postgres
      secureJsonData:
        password: ${POSTGRES_PASSWORD}
      jsonData:
        sslmode: 'require'
        maxOpenConns: 10
        maxIdleConns: 2
        connMaxLifetime: 14400

    - name: Loki
      type: loki
      access: proxy
      orgId: 1
      url: http://loki.monitoring.svc.cluster.local:3100
      basicAuth: false
      isDefault: false
      version: 1
      editable: false
---
# Global alerting configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: global-alertmanager-config
  namespace: monitoring
  labels:
    app.kubernetes.io/name: global-alertmanager
    app.kubernetes.io/part-of: hms
    app.kubernetes.io/component: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@hms.enterprise.com'
      smtp_auth_username: 'alerts@hms.enterprise.com'
      smtp_auth_password: '${SMTP_PASSWORD}'
      smtp_require_tls: true

    templates:
    - '/etc/alertmanager/templates/*.tmpl'

    route:
      group_by: ['alertname', 'severity', 'region']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        continue: true
      - match:
          severity: warning
        receiver: 'warning-alerts'
        continue: true
      - match_re:
          service: ^(patient|appointment|clinical|billing)$
        receiver: 'healthcare-alerts'
        continue: true
      - match:
          region: global
        receiver: 'global-alerts'
        continue: true

    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://127.0.0.1:5001/'
        send_resolved: true

    - name: 'critical-alerts'
      email_configs:
      - to: 'hms-ops-critical@hms.enterprise.com'
        subject: '[CRITICAL] {{ .GroupLabels.alertname }} - {{ .GroupLabels.region }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ .Labels }}
          Starts At: {{ .StartsAt }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_CRITICAL}'
        channel: '#hms-critical'
        title: '[CRITICAL] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

    - name: 'warning-alerts'
      email_configs:
      - to: 'hms-ops-warning@hms.enterprise.com'
        subject: '[WARNING] {{ .GroupLabels.alertname }} - {{ .GroupLabels.region }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ .Labels }}
          Starts At: {{ .StartsAt }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_WARNING}'
        channel: '#hms-warnings'
        title: '[WARNING] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

    - name: 'healthcare-alerts'
      email_configs:
      - to: 'hms-healthcare@hms.enterprise.com'
        subject: '[HEALTHCARE] {{ .GroupLabels.alertname }} - {{ .GroupLabels.service }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ .Labels }}
          Starts At: {{ .StartsAt }}
          {{ end }}

    - name: 'global-alerts'
      email_configs:
      - to: 'hms-global-ops@hms.enterprise.com'
        subject: '[GLOBAL] {{ .GroupLabels.alertname }} - {{ .GroupLabels.region }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ .Labels }}
          Starts At: {{ .StartsAt }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_GLOBAL}'
        channel: '#hms-global'
        title: '[GLOBAL] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'dev', 'instance']