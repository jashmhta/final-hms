name: Quality Assurance Pipeline

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'
  DJANGO_SETTINGS_MODULE: hms.settings_test

jobs:
  # Backend Testing
  backend-testing:
    name: Backend Testing
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: hms_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r backend/requirements.txt
        pip install -r backend/requirements-test.txt

    - name: Run pre-commit hooks
      run: |
        pre-commit run --all-files

    - name: Run security scanning
      run: |
        bandit -r backend/ -f json -o bandit-report.json || true
        safety check --json --output safety-report.json || true
        semgrep --config=auto --json --output=semgrep-report.json backend/ || true

    - name: Run database migrations
      run: |
        cd backend
        python manage.py migrate

    - name: Run unit tests
      run: |
        cd backend
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --cov-fail-under=95
        mv coverage.xml ../
        mv htmlcov/ ../

    - name: Run integration tests
      run: |
        cd backend
        pytest integration_tests/ -v --tb=short -m integration

    - name: Run HIPAA compliance tests
      run: |
        cd backend
        pytest backend/tests/test_hipaa_compliance.py -v --tb=short

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: backend
        name: backend-coverage

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  # Frontend Testing
  frontend-testing:
    name: Frontend Testing
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: ['18', '20']
        browser: ['chrome', 'firefox', 'webkit']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      run: |
        cd frontend
        npm ci

    - name: Run accessibility tests
      run: |
        cd frontend
        npm run test:accessibility

    - name: Run unit tests
      run: |
        cd frontend
        npm test -- --coverage --watchAll=false --passWithNoTests

    - name: Run E2E tests
      run: |
        cd frontend
        npm run test:e2e:${{ matrix.browser }}

    - name: Run visual regression tests
      run: |
        cd frontend
        npm run test:visual

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  # Performance Testing
  performance-testing:
    name: Performance Testing
    runs-on: ubuntu-latest
    needs: [backend-testing, frontend-testing]
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install locust psutil

    - name: Run load tests
      run: |
        cd backend
        locust --host=http://localhost:8000 --users=100 --spawn-rate=10 --run-time=1m --html=../locust-report.html

    - name: Run performance benchmarks
      run: |
        cd backend
        pytest tests/performance/ -v --benchmark-only --benchmark-json=../benchmark-results.json

    - name: Upload performance reports
      uses: actions/upload-artifact@v4
      with:
        name: performance-reports
        path: |
          locust-report.html
          benchmark-results.json

  # Security Testing
  security-testing:
    name: Security Testing
    runs-on: ubuntu-latest
    needs: [backend-testing, frontend-testing]
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run OWASP ZAP scan
      uses: zaproxy/action-baseline@v0.11.0
      with:
        target: 'http://localhost:8000'
        rules_file_name: '.zap/rules.tsv'
        cmd_options: '-a'

    - name: Run dependency vulnerability scan
      run: |
        npm audit --audit-level moderate
        pip-audit --requirement backend/requirements.txt --format json > audit-report.json

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-scan-reports
        path: |
          zap_report.html
          audit-report.json

  # API Contract Testing
  contract-testing:
    name: API Contract Testing
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install schemathesis pact-python

    - name: Run API contract testing
      run: |
        cd backend
        schemathesis run http://localhost:8000/api/schema/ --checks all --report=../contract-test-report.html

    - name: Upload contract test reports
      uses: actions/upload-artifact@v4
      with:
        name: contract-test-reports
        path: contract-test-report.html

  # Database Testing
  database-testing:
    name: Database Testing
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: hms_test
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r backend/requirements.txt

    - name: Run database validation tests
      run: |
        cd backend
        python manage.py validate_db_integrity
        python manage.py check_data_integrity

    - name: Run database performance tests
      run: |
        cd backend
        pytest tests/database_performance/ -v --benchmark-only

  # Cross-Browser Testing
  cross-browser-testing:
    name: Cross-Browser Testing
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      run: |
        cd frontend
        npm ci

    - name: Run cross-browser tests
      run: |
        cd frontend
        npx playwright test --project=chromium
        npx playwright test --project=firefox
        npx playwright test --project=webkit

    - name: Upload test results
      uses: actions/upload-artifact@v4
      with:
        name: cross-browser-test-results
        path: frontend/test-results/

  # Quality Gates
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [backend-testing, frontend-testing, performance-testing, security-testing, contract-testing, database-testing, cross-browser-testing]
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v4

    - name: Check test coverage
      run: |
        python -c "
        import xml.etree.ElementTree as ET
        tree = ET.parse('coverage.xml')
        root = tree.getroot()
        coverage = float(root.get('line-rate')) * 100
        if coverage < 95:
            print(f'Coverage {coverage}% is below 95% threshold')
            exit(1)
        print(f'Coverage {coverage}% meets 95% threshold')
        "

    - name: Check security issues
      run: |
        python -c "
        import json
        with open('bandit-report.json') as f:
            bandit_results = json.load(f)
        with open('safety-report.json') as f:
            safety_results = json.load(f)

        if bandit_results.get('errors', []):
            print('Bandit scan failed:', bandit_results['errors'])
            exit(1)

        critical_issues = [vuln for vuln in safety_results if vuln.get('severity') == 'critical']
        if critical_issues:
            print('Critical security issues found:', critical_issues)
            exit(1)

        print('All security checks passed')
        "

    - name: Generate quality report
      run: |
        cat > quality-report.md << EOF
        # Quality Assurance Report

        ## Test Results
        - Backend Coverage: $(python -c "import xml.etree.ElementTree as ET; tree=ET.parse('coverage.xml'); print(f'{float(tree.getroot().get(\"line-rate\"))*100:.1f}%')")
        - Frontend Coverage: $(python -c "import json; with open('frontend/coverage/coverage-summary.json') as f: data=json.load(f); print(f'{data[\"total\"][\"lines\"][\"pct\"]:.1f}%')")

        ## Security Status
        - Bandit: $(python -c "import json; with open('bandit-report.json') as f: data=json.load(f); print(f'{len(data[\"results\"])} issues found')")
        - Safety: $(python -c "import json; with open('safety-report.json') as f: data=json.load(f); print(f'{len(data)} vulnerabilities')")
        - OWASP ZAP: $(python -c "import json; with open('zap_report.json') as f: data=json.load(f); print(f'{len(data[\"alerts\"])} alerts')")

        ## Performance Metrics
        - API Response Time: $(python -c "import json; with open('benchmark-results.json') as f: data=json.load(f); print(f'{data[\"mean\"]:.2f}ms')")
        - Throughput: $(python -c "import json; with open('locust-report.html') as f: print('N/A')")

        Generated on: $(date)
        EOF

    - name: Upload quality report
      uses: actions/upload-artifact@v4
      with:
        name: quality-report
        path: quality-report.md

    - name: Fail on quality issues
      run: |
        # This step will fail if any of the previous steps failed
        echo "Quality gates completed"

  # Zero-Bug Policy Enforcement
  zero-bug-policy:
    name: Zero-Bug Policy
    runs-on: ubuntu-latest
    needs: quality-gates
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check for any failing tests
      run: |
        echo "Enforcing zero-bug policy..."

        # Check if any tests failed
        if [ "${{ needs.backend-testing.result }}" != "success" ]; then
          echo "Backend tests failed - blocking deployment"
          exit 1
        fi

        if [ "${{ needs.frontend-testing.result }}" != "success" ]; then
          echo "Frontend tests failed - blocking deployment"
          exit 1
        fi

        if [ "${{ needs.security-testing.result }}" != "success" ]; then
          echo "Security tests failed - blocking deployment"
          exit 1
        fi

        echo "All tests passed - zero-bug policy satisfied"

    - name: Generate deployment ticket
      if: success()
      run: |
        cat > deployment-ready.md << EOF
        # Deployment Ready Ticket

        **Status**: ✅ Approved for deployment
        **Date**: $(date)
        **Commit**: ${{ github.sha }}

        ## Quality Metrics
        - Test Coverage: >95%
        - Security Scan: No critical issues
        - Performance: Within SLA
        - All Tests: Passing

        This deployment meets zero-bug policy requirements.
        EOF

    - name: Upload deployment ticket
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: deployment-ticket
        path: deployment-ready.md